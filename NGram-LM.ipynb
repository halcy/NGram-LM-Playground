{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Playground\n",
    "\n",
    "N-Gram language models model the structure of a language by modeling the probabilities of words depending on a history of the previous n - 1 words. This simple approach, with a statistical model that is extremely easy to estimate from some givent text, nevertheless manages to capture a good deal of what makes language language.\n",
    "\n",
    "N-Gram language models can be used to estimate the probability of a given sentence (\"how likely am I to see this sentence in this language\"). They can also be used generatively, by starting with a seed phrase and then picking additional words according to the probability the n-gram LM would assign them given the current context.\n",
    "\n",
    "This file contains some code to estimate an n-gram LM from a given text or some hard-coded sentences, which can then be used to estimate the probability of a sentence. It also contains code for generating text, which can also be used to verify the probability of a sentence actually appearing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings\n",
    "order gives the maximum order of the n-grams (i.e. the n in n-gram). readText sets whether to use hard-coded text for training, or to read text in from a file (The suggested file can be found at http://textfiles.com/100/hack11a.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order = 2\n",
    "readText = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "if readText == False:\n",
    "    # Hardcoded sentences\n",
    "    trainData = [\"john read her book\", \"i read a different book\", \"john read a book by mulan\"]\n",
    "else:\n",
    "    # From http://textfiles.com/100/hack11a.txt\n",
    "    trainDataFile = \"hack11a.txt\" # Hacker Crackdown, by Bruce Sterling, January, 1994 [textfiles.com / project gutenberg]\n",
    "    \n",
    "    # Read and clean a bit (remove special chars, newlines, ...)\n",
    "    with open(trainDataFile, 'r') as myfile:\n",
    "        trainDataString = myfile.read().replace('\\n', ' ')\n",
    "    trainDataString = trainDataString.lower()\n",
    "    trainDataString = trainDataString.replace('\"', \"\")\n",
    "    trainDataString = trainDataString.replace(',', \"\")\n",
    "    trainDataString = trainDataString.replace(';', \"\")\n",
    "    trainDataString = trainDataString.replace(':', \"\")\n",
    "    trainDataString = trainDataString.replace(':', \"\")\n",
    "    trainDataString = trainDataString.replace('(', \"\")\n",
    "    trainDataString = trainDataString.replace(')', \"\")\n",
    "    trainDataString = trainDataString.replace('-', \" \")\n",
    "    trainDataString = re.sub(\"\\s\\s+\" , \" \", trainDataString)\n",
    "    trainData = trainDataString.split(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate n-gram probabilities\n",
    "\n",
    "This is done iteratively: First, unigram (1-gram) probabilities are estimated, then, using those, bigram (2-gram) probabilities, then trigram probabilities etc., up to the desired order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'</s>': 0.14285714285714285,\n",
      "  '<s>': 0.14285714285714285,\n",
      "  'a': 0.09523809523809523,\n",
      "  'book': 0.14285714285714285,\n",
      "  'by': 0.047619047619047616,\n",
      "  'different': 0.047619047619047616,\n",
      "  'her': 0.047619047619047616,\n",
      "  'i': 0.047619047619047616,\n",
      "  'john': 0.09523809523809523,\n",
      "  'mulan': 0.047619047619047616,\n",
      "  'read': 0.14285714285714285},\n",
      " {'<s> i': 0.3333333333333333,\n",
      "  '<s> john': 0.6666666666666666,\n",
      "  'a book': 0.5,\n",
      "  'a different': 0.5,\n",
      "  'book </s>': 0.6666666666666666,\n",
      "  'book by': 0.3333333333333333,\n",
      "  'by mulan': 1.0,\n",
      "  'different book': 1.0,\n",
      "  'her book': 1.0,\n",
      "  'i read': 1.0,\n",
      "  'john read': 1.0,\n",
      "  'mulan </s>': 1.0,\n",
      "  'read a': 0.6666666666666666,\n",
      "  'read her': 0.3333333333333333}]\n"
     ]
    }
   ],
   "source": [
    "tokenizedData = []\n",
    "for sentence in trainData:\n",
    "    tokenizedData.append([\"<s>\"] + sentence.strip().split() + [\"</s>\"])\n",
    "    \n",
    "ngrams = []\n",
    "ngramCounts = []\n",
    "for n in range(order):\n",
    "    thisnGramCounts = {}\n",
    "    totalCount = 0\n",
    "    for sentence in tokenizedData:\n",
    "        for ngramStart in range(len(sentence) - n):\n",
    "            ngram = sentence[ngramStart:ngramStart + n + 1]\n",
    "            ngramStr = \" \".join(ngram)\n",
    "            if not ngramStr in thisnGramCounts:\n",
    "                thisnGramCounts[ngramStr] = 0\n",
    "            thisnGramCounts[ngramStr] += 1\n",
    "            totalCount += 1\n",
    "    ngramCounts.append(thisnGramCounts)\n",
    "    \n",
    "    thisNgrams = {}\n",
    "    thisNgramsByPrefix = {}\n",
    "    ngramDivisor = totalCount\n",
    "    for ngramStr in thisnGramCounts.keys():\n",
    "        ngramPrefix = \" \".join(ngramStr.split()[:-1])\n",
    "        if n != 0:\n",
    "            ngramDivisor = ngramCounts[n - 1][ngramPrefix]\n",
    "        ngramProb = ngramCounts[n][ngramStr] / ngramDivisor\n",
    "        thisNgrams[ngramStr] = ngramProb\n",
    "    ngrams.append(thisNgrams)\n",
    "    \n",
    "if readText == False:\n",
    "    pprint.pprint(ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings for evaluation\n",
    "\n",
    "The testSentence is the sentence for which the probability is to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testSentence = \"john read a book\"\n",
    "#testSentence = \"hackers are mostly from computer companies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of probabilities\n",
    "\n",
    "Note that if the test sentence contains n-grams not seen in training, this will break. There are techniques to mitigate this, but they are not implemented here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of n-gram \"<s> john\" is 0.6666666666666666\n",
      "Probability of n-gram \"john read\" is 1.0\n",
      "Probability of n-gram \"read a\" is 0.6666666666666666\n",
      "Probability of n-gram \"a book\" is 0.5\n",
      "Probability of n-gram \"book </s>\" is 0.6666666666666666\n",
      "Probability of sentence \"john read a book\" is 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "sentenceProb = 1.0\n",
    "testSentenceTokenized = [\"<s>\"] + testSentence.split() + [\"</s>\"]\n",
    "for ngramStart in range(len(testSentenceTokenized) - order + 1):\n",
    "    ngram = testSentenceTokenized[ngramStart:ngramStart + order]\n",
    "    ngramStr = \" \".join(ngram)\n",
    "    print(\"Probability of n-gram \\\"\" + ngramStr + \"\\\" is \" + str(ngrams[order - 1][ngramStr]))\n",
    "    sentenceProb *= ngrams[order - 1][ngramStr]\n",
    "print(\"Probability of sentence \\\"\" + testSentence + \"\\\" is \" + str(sentenceProb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index by prefix\n",
    "\n",
    "Indexes the n-grams by prefix so the generation step can quickly pick the right n-grams for a given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngramsByPrefix = {}\n",
    "for ngramStr in ngrams[order - 1].keys():\n",
    "    ngramPrefix = \" \".join(ngramStr.split()[:-1])\n",
    "    if ngramPrefix not in ngramsByPrefix:\n",
    "        ngramsByPrefix[ngramPrefix] = {}\n",
    "    ngramsByPrefix[ngramPrefix][ngramStr] = ngrams[order - 1][ngramStr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation settings\n",
    "\n",
    "howMany controls how many sentences are generated. The seed is the initial context from which to  start. Note that the prefix has to be at least n - 1 words long for this to work. Try cranking the number of generated sentences up to see the observed probability of encountering the test sentence approach the value calculated for it above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "howMany = 10\n",
    "seed = \"<s>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john read her book by mulan\n",
      "john read a book by mulan\n",
      "john read a book\n",
      "john read her book\n",
      "i read a book\n",
      "john read a book\n",
      "i read a book by mulan\n",
      "i read a book by mulan\n",
      "john read a different book\n",
      "i read her book by mulan\n",
      "Observed likelihood of test sentence: 0.2\n"
     ]
    }
   ],
   "source": [
    "testSentenceSeenCount = 0\n",
    "for i in range(howMany):\n",
    "    result = seed\n",
    "    while(result.split()[-1] != \"</s>\"):\n",
    "        ngramPrefix = \" \".join(result.split()[-order+1:])\n",
    "        potentialNextNgrams = ngramsByPrefix[ngramPrefix]\n",
    "        potentialNextNgramsStrs = list(potentialNextNgrams.keys())\n",
    "        potentialNextNgramsProbs = np.array(list(potentialNextNgrams.values()))\n",
    "        potentialNextNgramsProbs = potentialNextNgramsProbs / np.sum(potentialNextNgramsProbs)\n",
    "        ngramIndex = np.random.choice(potentialNextNgramsProbs.shape[0], 1, p = potentialNextNgramsProbs)[0]\n",
    "        nextNgramSuffix = \" \".join(potentialNextNgramsStrs[ngramIndex].split()[-1:])\n",
    "        result += \" \" + nextNgramSuffix\n",
    "    \n",
    "    result = \" \".join(result.split()[1:-1])\n",
    "    if howMany < 100:\n",
    "        print(result)\n",
    "        \n",
    "    if result == testSentence:\n",
    "        testSentenceSeenCount += 1\n",
    "        \n",
    "print(\"Observed likelihood of test sentence: \" + str(testSentenceSeenCount / howMany))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
